{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "import emnist\n",
    "from emnist import extract_training_samples, extract_test_samples\n",
    "\n",
    "t_images, t_labels = extract_training_samples('digits')\n",
    "v_images, v_labels = extract_test_samples('digits')\n",
    "\n",
    "#print(t_images.shape)\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,)),])\n",
    "#transform = transforms.Compose([transforms.Normalize((0.1307,), (0.3081,)),])\n",
    "#print(t_images.shape)\n",
    "t_images = [t_images[i] for i in range(len(t_images))]\n",
    "t_images = np.array(t_images)\n",
    "#print(t_images.shape)\n",
    "t_images = [np.array(transform(t_images[i])) for i in range(len(t_images))]\n",
    "t_images = np.array(t_images)\n",
    "print(t_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.3987565  -0.3987565\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.33511534  0.1612858   1.7268586   1.7395868\n",
      "    0.55586106 -0.41148472 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.16964827  1.6504892   2.681476    2.8087585   2.8087585\n",
      "    2.668748   -0.01690946 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.38602826\n",
      "    1.1413597   2.7196608   2.8087585   2.8214867   2.8214867\n",
      "    2.7578456   0.07218818 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.41148472  0.17401403  1.5995764\n",
      "    2.7196608   2.8087585   2.8214867   2.8214867   2.8214867\n",
      "    2.8087585   1.6504892  -0.00418122 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296  0.7213281   2.681476    2.8087585\n",
      "    2.8087585   2.8087585   2.8087585   2.8087585   2.7069325\n",
      "    2.5796502   2.7451172   1.1668162  -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.37330002  2.1468904   2.8087585   2.8087585\n",
      "    2.8087585   2.8087585   2.7069325   2.1723468   1.2050011\n",
      "    1.6250328   2.7578456   1.1922727  -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.14419182  2.5414655   2.8214867   2.8087585\n",
      "    2.566922    1.5995764   0.17401403 -0.37330002 -0.29693064\n",
      "    2.3759985   2.7578456   1.1922727  -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.37330002  1.0268056   2.8087585   2.8087585   2.5541937\n",
      "    0.58131754 -0.3987565  -0.42421296 -0.33511534  0.7849693\n",
      "    2.7705739   2.7578456   1.1922727  -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.37330002  1.1922727   2.8087585   2.7705739   1.4213811\n",
      "   -0.33511534 -0.42421296 -0.42421296  0.00854701  2.1468904\n",
      "    2.8087585   2.7451172   1.1668162  -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.37330002  1.0268056   2.8087585   2.7578456   1.1922727\n",
      "   -0.42421296 -0.42421296 -0.01690946  1.8159562   2.7196608\n",
      "    2.8087585   1.6504892  -0.00418122 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296  0.00854701  2.6942043   2.7578456   1.3704681\n",
      "   -0.3987565   0.03400347  1.803228    2.8087585   2.8087585\n",
      "    2.350542   -0.14419182 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.3223871   2.2105315   2.8087585   2.3887267\n",
      "    0.41585052  1.803228    2.7069325   2.8087585   2.783302\n",
      "    0.7976975  -0.41148472 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296  0.17401403  2.7069325   2.8087585\n",
      "    2.7705739   2.8087585   2.8087585   2.8087585   2.5287373\n",
      "   -0.15692005 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.30965886  2.401455    2.8087585\n",
      "    2.8214867   2.8087585   2.8087585   2.401455    1.5359352\n",
      "   -0.37330002 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.41148472  0.18674228  2.5541937   2.8087585\n",
      "    2.8214867   2.8087585   2.5541937   0.03400347 -0.38602826\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.33511534\n",
      "    0.21219873  1.2050011   2.681476    2.8087585   2.7578456\n",
      "    2.7705739   2.8087585   2.401455   -0.30965886 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.37330002  0.58131754\n",
      "    2.3759985   2.7069325   2.8087585   2.3887267   1.3704681\n",
      "    1.4595658   2.783302    2.7069325   0.1612858  -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.14419182  1.5995764   2.5541937\n",
      "    2.8087585   2.8087585   2.6560197   0.17401403 -0.41148472\n",
      "    1.0268056   2.8087585   2.8087585   1.1668162  -0.37330002\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.3987565   0.42857873  2.3759985   2.8087585   2.8087585\n",
      "    2.5287373   1.2559141   0.00854701 -0.3987565  -0.00418122\n",
      "    1.9814233   2.8087585   2.8087585   1.0268056  -0.37330002\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.15692005  1.7395868   2.8087585   2.8087585   2.7069325\n",
      "    1.1413597  -0.14419182 -0.41148472  0.17401403  1.6504892\n",
      "    2.7705739   2.8087585   2.7069325   0.1612858  -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "    0.04673171  2.3378139   2.8087585   2.4141831   0.7595128\n",
      "   -0.38602826 -0.3605718   0.73405635  2.681476    2.8087585\n",
      "    2.8087585   2.7196608   1.9941516  -0.37330002 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.15692005  1.7395868   2.8087585   2.5796502   1.7777716\n",
      "    1.7650434   2.3250856   2.7196608   2.8087585   2.8087585\n",
      "    2.5287373   0.73405635 -0.29693064 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.38602826  0.5685893   2.5287373   2.7960303   2.783302\n",
      "    2.783302    2.8087585   2.8087585   2.6942043   2.3759985\n",
      "    0.7849693  -0.33511534 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.14419182  1.0268056   1.3577399\n",
      "    2.1468904   1.3577399   1.0268056   0.00854701 -0.30965886\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.38602826 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296]\n",
      "  [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "   -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -0.42421296 -0.42421296 -0.42421296]]]\n"
     ]
    }
   ],
   "source": [
    "#t_images = np.array(t_images)\n",
    "#print(t_images[0])\n",
    "#trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, train=True)#, transform=transform)\n",
    "#valset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, train=False)#, transform=transform)\n",
    "#print(trainset[1])\n",
    "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "#valloader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 100, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "b_im = []\n",
    "b_val = []\n",
    "for i in range(len(t_images)//batch_size):\n",
    "    b_im.append(t_images[i*batch_size:(i+1)*batch_size])\n",
    "    b_val.append(t_labels[i*batch_size:(i+1)*batch_size])\n",
    "\n",
    "\n",
    "b_im = np.array(b_im)\n",
    "b_val = np.array(b_val)\n",
    "\n",
    "print(b_im.shape)\n",
    "\n",
    "#dataiter = iter(trainloader)\n",
    "#images, labels = dataiter.next()\n",
    "\n",
    "#print(images.shape)\n",
    "#print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (5): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [512, 256]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1, 28, 28)\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100, 10])\n",
      "torch.Size([100])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-0f407dfafe6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_b_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_b_val\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#calculate the NLL loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use tensor.item() to convert a 0-dim tensor to a Python number"
     ]
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "#images, labels = next(iter(trainloader))\n",
    "t_b_im = b_im[0]\n",
    "print(t_b_im.shape)\n",
    "t_b_im = torch.FloatTensor(t_b_im)\n",
    "print(t_b_im.shape)\n",
    "t_b_im = t_b_im.view(t_b_im.shape[0], -1)\n",
    "\n",
    "print(t_b_im.shape)\n",
    "\n",
    "logps = model(t_b_im) #log probabilities\n",
    "print(logps.shape)\n",
    "t_b_val = torch.LongTensor(b_val)\n",
    "print(t_b_val[0].shape)\n",
    "loss = criterion(logps, t_b_val[0]) #calculate the NLL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.0007653717748976002\n",
      "Epoch 1 - Training loss: 0.0005163749136050076\n",
      "Epoch 2 - Training loss: 0.000398329069869942\n",
      "Epoch 3 - Training loss: 0.0003253897322584332\n",
      "Epoch 4 - Training loss: 0.00027344296434651675\n",
      "Epoch 5 - Training loss: 0.0002330566487435135\n",
      "Epoch 6 - Training loss: 0.00020036222910857759\n",
      "Epoch 7 - Training loss: 0.0001724865258295419\n",
      "Epoch 8 - Training loss: 0.00014865588336566968\n",
      "Epoch 9 - Training loss: 0.00012831365463074083\n",
      "Epoch 10 - Training loss: 0.00011101553170907815\n",
      "Epoch 11 - Training loss: 9.592829292099244e-05\n",
      "Epoch 12 - Training loss: 8.305566710320515e-05\n",
      "Epoch 13 - Training loss: 7.207946481254719e-05\n",
      "Epoch 14 - Training loss: 6.234267856340618e-05\n",
      "Epoch 15 - Training loss: 5.426554122010809e-05\n",
      "Epoch 16 - Training loss: 4.7221810780380714e-05\n",
      "Epoch 17 - Training loss: 4.125750026766279e-05\n",
      "Epoch 18 - Training loss: 3.5954337038159183e-05\n",
      "Epoch 19 - Training loss: 3.1504822114053844e-05\n",
      "Epoch 20 - Training loss: 2.7573522165873025e-05\n",
      "Epoch 21 - Training loss: 2.4376514721742146e-05\n",
      "Epoch 22 - Training loss: 2.162598308603568e-05\n",
      "Epoch 23 - Training loss: 1.932488226439091e-05\n",
      "Epoch 24 - Training loss: 1.742275473130424e-05\n",
      "\n",
      "Training Time (in minutes) = 17.690243140856424\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.004, momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 25\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in zip(b_im, b_val):\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "#         f_im = []\n",
    "#         for i in range(batch_size):\n",
    "#             k = []\n",
    "#             for j in range(28):\n",
    "#                 k += list(images[i][j])\n",
    "#             f_im.append(k)\n",
    "#         images = f_im\n",
    "#         images = np.array(images)\n",
    "#         trans = transforms.Compose([transforms.ToTensor()])\n",
    "#         images = trans(images)\n",
    "#         labels = torch.from_numpy(labels)\n",
    "        images = torch.FloatTensor(images)\n",
    "        #print(t_b_im.shape)\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        #print(images.shape)\n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        \n",
    "        labels = torch.LongTensor(labels)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(t_images)))\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def view_classify(img, ps):\n",
    "#     ''' Function for viewing an image and it's predicted classes.\n",
    "#     '''\n",
    "#     ps = ps.data.numpy().squeeze()\n",
    "\n",
    "#     fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "#     ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "#     ax1.axis('off')\n",
    "#     ax2.barh(np.arange(10), ps)\n",
    "#     ax2.set_aspect(0.1)\n",
    "#     ax2.set_yticks(np.arange(10))\n",
    "#     ax2.set_yticklabels(np.arange(10))\n",
    "#     ax2.set_title('Class Probability')\n",
    "#     ax2.set_xlim(0, 1.1)\n",
    "#     plt.tight_layout()\n",
    "    \n",
    "# images, labels = next(iter(valloader))\n",
    "\n",
    "# img = images[0].view(1, 784)\n",
    "# with torch.no_grad():\n",
    "#     logps = model(img)\n",
    "\n",
    "# ps = torch.exp(logps)\n",
    "# probab = list(ps.numpy()[0])\n",
    "# print(\"Predicted Digit =\", probab.index(max(probab)))\n",
    "# view_classify(img.view(1, 28, 28), ps)\n",
    "\n",
    "#transform = transforms.Compose([transforms.Normalize((0.1307,), (0.3081,)),])\n",
    "#print(t_images.shape)\n",
    "v_images = [v_images[i] for i in range(len(v_images))]\n",
    "v_images = np.array(v_images)\n",
    "#print(t_images.shape)\n",
    "v_images = [np.array(transform(v_images[i])) for i in range(len(v_images))]\n",
    "v_images = np.array(v_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 100, 1, 28, 28)\n",
      "(400, 100)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "v_im = []\n",
    "v_val = []\n",
    "for i in range(len(v_images)//batch_size):\n",
    "    v_im.append(v_images[i*batch_size:(i+1)*batch_size])\n",
    "    v_val.append(v_labels[i*batch_size:(i+1)*batch_size])\n",
    "\n",
    "\n",
    "v_im = np.array(v_im)\n",
    "v_val = np.array(v_val)\n",
    "\n",
    "print(v_im.shape)\n",
    "print(v_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count, all_count = 0, 0\n",
    "for images, labels in zip(v_im, v_val):\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "#         f_im = []\n",
    "#         for i in range(batch_size):\n",
    "#             k = []\n",
    "#             for j in range(28):\n",
    "#                 k += list(images[i][j])\n",
    "#             f_im.append(k)\n",
    "#         images = f_im\n",
    "#         images = np.array(images)\n",
    "#         trans = transforms.Compose([transforms.ToTensor()])\n",
    "#         images = trans(images)\n",
    "#         labels = torch.from_numpy(labels)\n",
    "        images = torch.FloatTensor(images)\n",
    "        #print(t_b_im.shape)\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        #print(images.shape)\n",
    "        # Training pass\n",
    "        with torch.no_grad():\n",
    "            logps = model(images)\n",
    "        #print(logps.shape, logps[0])\n",
    "        ps = torch.exp(logps)\n",
    "        #print(ps.shape)\n",
    "        for i in range(batch_size):\n",
    "            prob_ans = ps[i]\n",
    "            prob_ans = list(prob_ans)\n",
    "            pred_label = prob_ans.index(max(prob_ans))\n",
    "            #pred_label = ps.index(max(ps))\n",
    "            true_label = labels[i]\n",
    "            if(true_label == pred_label):\n",
    "              correct_count += 1\n",
    "            all_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "0.99095\n"
     ]
    }
   ],
   "source": [
    "print(all_count)\n",
    "print(correct_count/all_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './99percent_emnist_model_06102019.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
