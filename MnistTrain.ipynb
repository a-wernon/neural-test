{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (5): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [512, 256]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images) #log probabilities\n",
    "loss = criterion(logps, labels) #calculate the NLL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.5831726135284916\n",
      "Epoch 1 - Training loss: 0.2321204259229113\n",
      "Epoch 2 - Training loss: 0.17106516316914355\n",
      "Epoch 3 - Training loss: 0.13385640377842034\n",
      "Epoch 4 - Training loss: 0.10867923103384118\n",
      "Epoch 5 - Training loss: 0.09067444769002354\n",
      "Epoch 6 - Training loss: 0.07641201652189307\n",
      "Epoch 7 - Training loss: 0.06542316116472043\n",
      "Epoch 8 - Training loss: 0.05670936718217727\n",
      "Epoch 9 - Training loss: 0.0494912936171489\n",
      "Epoch 10 - Training loss: 0.04263791311651405\n",
      "Epoch 11 - Training loss: 0.03783205576113927\n",
      "Epoch 12 - Training loss: 0.03286062066020297\n",
      "Epoch 13 - Training loss: 0.028983846636437403\n",
      "Epoch 14 - Training loss: 0.025472780955689295\n",
      "Epoch 15 - Training loss: 0.02262102411007449\n",
      "Epoch 16 - Training loss: 0.01979400231234872\n",
      "Epoch 17 - Training loss: 0.017468960304408948\n",
      "Epoch 18 - Training loss: 0.015474496520499684\n",
      "Epoch 19 - Training loss: 0.013724511651111755\n",
      "Epoch 20 - Training loss: 0.012363314030886585\n",
      "Epoch 21 - Training loss: 0.010846605487684133\n",
      "Epoch 22 - Training loss: 0.009880712718518177\n",
      "Epoch 23 - Training loss: 0.008739361188003123\n",
      "Epoch 24 - Training loss: 0.007898510477420236\n",
      "\n",
      "Training Time (in minutes) = 19.983859340349834\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.004, momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 25\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Digit = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def view_classify(img, ps):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    ax2.set_yticklabels(np.arange(10))\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "images, labels = next(iter(valloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "ps = torch.exp(logps)\n",
    "probab = list(ps.numpy()[0])\n",
    "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
    "view_classify(img.view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number Of Images Tested = 10000\n",
      "\n",
      "Model Accuracy = 0.9813\n"
     ]
    }
   ],
   "source": [
    "correct_count, all_count = 0, 0\n",
    "for images,labels in valloader:\n",
    "  for i in range(len(labels)):\n",
    "    img = images[i].view(1, 784)\n",
    "    with torch.no_grad():\n",
    "        logps = model(img)\n",
    "\n",
    "    \n",
    "    ps = torch.exp(logps)\n",
    "    probab = list(ps.numpy()[0])\n",
    "    pred_label = probab.index(max(probab))\n",
    "    true_label = labels.numpy()[i]\n",
    "    if(true_label == pred_label):\n",
    "      correct_count += 1\n",
    "    all_count += 1\n",
    "\n",
    "print(\"Number Of Images Tested =\", all_count)\n",
    "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './2l_mnist_model_large_fin_2609.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
